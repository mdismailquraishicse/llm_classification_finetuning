{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1102ebc5-3f1b-4f72-9dc8-6e2fa6b30610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7530b7a0-1a99-47c6-bc04-a40955207b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\",None)\n",
    "pd.set_option(\"display.max_columns\",None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c429a71d-3a0a-4ec9-a070-0a6e401d13cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/train.csv\"\n",
    "df= pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25431cbc-0275-457e-b352-a9ac279ca17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (57477, 9)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "columns: Index(['id', 'model_a', 'model_b', 'prompt', 'response_a', 'response_b',\n",
      "       'winner_model_a', 'winner_model_b', 'winner_tie'],\n",
      "      dtype='object')\n",
      "----------------------------------------------------------------------------------------------------\n",
      "      id             model_a         model_b  \\\n",
      "0  30192  gpt-4-1106-preview      gpt-4-0613   \n",
      "1  53567           koala-13b      gpt-4-0613   \n",
      "2  65089  gpt-3.5-turbo-0613  mistral-medium   \n",
      "\n",
      "                                              prompt  \\\n",
      "0  [\"Is it morally right to try to have a certain...   \n",
      "1  [\"What is the difference between marriage lice...   \n",
      "2  [\"explain function calling. how would you call...   \n",
      "\n",
      "                                          response_a  \\\n",
      "0  [\"The question of whether it is morally right ...   \n",
      "1  [\"A marriage license is a legal document that ...   \n",
      "2  [\"Function calling is the process of invoking ...   \n",
      "\n",
      "                                          response_b  winner_model_a  \\\n",
      "0  [\"As an AI, I don't have personal beliefs or o...               1   \n",
      "1  [\"A marriage license and a marriage certificat...               0   \n",
      "2  [\"Function calling is the process of invoking ...               0   \n",
      "\n",
      "   winner_model_b  winner_tie  \n",
      "0               0           0  \n",
      "1               1           0  \n",
      "2               0           1  \n"
     ]
    }
   ],
   "source": [
    "print(f\"shape: {df.shape}\")\n",
    "print(\"-\"*100)\n",
    "print(f\"columns: {df.columns}\")\n",
    "print(\"-\"*100)\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aba6ec58-6d58-4085-9aa0-2981a274f129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57477 entries, 0 to 57476\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   id              57477 non-null  int64 \n",
      " 1   model_a         57477 non-null  object\n",
      " 2   model_b         57477 non-null  object\n",
      " 3   prompt          57477 non-null  object\n",
      " 4   response_a      57477 non-null  object\n",
      " 5   response_b      57477 non-null  object\n",
      " 6   winner_model_a  57477 non-null  int64 \n",
      " 7   winner_model_b  57477 non-null  int64 \n",
      " 8   winner_tie      57477 non-null  int64 \n",
      "dtypes: int64(4), object(5)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fd0f573-e833-4925-b7f7-150d8cc76ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.747700e+04</td>\n",
       "      <td>57477.000000</td>\n",
       "      <td>57477.000000</td>\n",
       "      <td>57477.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.142564e+09</td>\n",
       "      <td>0.349079</td>\n",
       "      <td>0.341911</td>\n",
       "      <td>0.309011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.238327e+09</td>\n",
       "      <td>0.476683</td>\n",
       "      <td>0.474354</td>\n",
       "      <td>0.462090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.019200e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.071821e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.133658e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.211645e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.294947e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  winner_model_a  winner_model_b    winner_tie\n",
       "count  5.747700e+04    57477.000000    57477.000000  57477.000000\n",
       "mean   2.142564e+09        0.349079        0.341911      0.309011\n",
       "std    1.238327e+09        0.476683        0.474354      0.462090\n",
       "min    3.019200e+04        0.000000        0.000000      0.000000\n",
       "25%    1.071821e+09        0.000000        0.000000      0.000000\n",
       "50%    2.133658e+09        0.000000        0.000000      0.000000\n",
       "75%    3.211645e+09        1.000000        1.000000      1.000000\n",
       "max    4.294947e+09        1.000000        1.000000      1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f30195c1-cbc2-4a49-b475-f1f951f762e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_colwise(df,col):\n",
    "    x= df[col].value_counts().reset_index()\n",
    "    x.index= x[col]\n",
    "    x.drop(col, axis=1, inplace=True)\n",
    "    return x\n",
    "\n",
    "model_a_vc= get_count_colwise(df.copy(), \"model_a\")\n",
    "model_b_vc= get_count_colwise(df.copy(), \"model_b\")\n",
    "winner_a_count= get_count_colwise(df.copy(), \"winner_model_a\")\n",
    "winner_b_count= get_count_colwise(df.copy(), \"winner_model_b\")\n",
    "winner_tie_count= get_count_colwise(df.copy(), \"winner_tie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c9e6542-60c8-4f90-a082-e319d9780c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>model_a</th>\n",
       "      <th>gpt-4-1106-preview</th>\n",
       "      <th>gpt-3.5-turbo-0613</th>\n",
       "      <th>gpt-4-0613</th>\n",
       "      <th>claude-2.1</th>\n",
       "      <th>gpt-4-0314</th>\n",
       "      <th>claude-instant-1</th>\n",
       "      <th>claude-1</th>\n",
       "      <th>vicuna-33b</th>\n",
       "      <th>mixtral-8x7b-instruct-v0.1</th>\n",
       "      <th>mistral-medium</th>\n",
       "      <th>vicuna-13b</th>\n",
       "      <th>gpt-3.5-turbo-1106</th>\n",
       "      <th>llama-2-70b-chat</th>\n",
       "      <th>llama-2-13b-chat</th>\n",
       "      <th>claude-2.0</th>\n",
       "      <th>zephyr-7b-beta</th>\n",
       "      <th>palm-2</th>\n",
       "      <th>llama-2-7b-chat</th>\n",
       "      <th>openchat-3.5</th>\n",
       "      <th>mistral-7b-instruct</th>\n",
       "      <th>wizardlm-70b</th>\n",
       "      <th>wizardlm-13b</th>\n",
       "      <th>koala-13b</th>\n",
       "      <th>vicuna-7b</th>\n",
       "      <th>oasst-pythia-12b</th>\n",
       "      <th>codellama-34b-instruct</th>\n",
       "      <th>gemini-pro-dev-api</th>\n",
       "      <th>gemini-pro</th>\n",
       "      <th>pplx-70b-online</th>\n",
       "      <th>alpaca-13b</th>\n",
       "      <th>yi-34b-chat</th>\n",
       "      <th>gpt-3.5-turbo-0314</th>\n",
       "      <th>chatglm-6b</th>\n",
       "      <th>pplx-7b-online</th>\n",
       "      <th>RWKV-4-Raven-14B</th>\n",
       "      <th>tulu-2-dpo-70b</th>\n",
       "      <th>gpt-4-0125-preview</th>\n",
       "      <th>starling-lm-7b-alpha</th>\n",
       "      <th>qwen-14b-chat</th>\n",
       "      <th>chatglm3-6b</th>\n",
       "      <th>stripedhyena-nous-7b</th>\n",
       "      <th>fastchat-t5-3b</th>\n",
       "      <th>openhermes-2.5-mistral-7b</th>\n",
       "      <th>mpt-7b-chat</th>\n",
       "      <th>solar-10.7b-instruct-v1.0</th>\n",
       "      <th>deepseek-llm-67b-chat</th>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <th>dolly-v2-12b</th>\n",
       "      <th>stablelm-tuned-alpha-7b</th>\n",
       "      <th>guanaco-33b</th>\n",
       "      <th>llama2-70b-steerlm-chat</th>\n",
       "      <th>mpt-30b-chat</th>\n",
       "      <th>chatglm2-6b</th>\n",
       "      <th>qwen1.5-72b-chat</th>\n",
       "      <th>llama-13b</th>\n",
       "      <th>gpt4all-13b-snoozy</th>\n",
       "      <th>zephyr-7b-alpha</th>\n",
       "      <th>dolphin-2.2.1-mistral-7b</th>\n",
       "      <th>nous-hermes-2-mixtral-8x7b-dpo</th>\n",
       "      <th>falcon-180b-chat</th>\n",
       "      <th>openchat-3.5-0106</th>\n",
       "      <th>qwen1.5-7b-chat</th>\n",
       "      <th>qwen1.5-4b-chat</th>\n",
       "      <th>mistral-7b-instruct-v0.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3678</td>\n",
       "      <td>3553</td>\n",
       "      <td>3099</td>\n",
       "      <td>2859</td>\n",
       "      <td>2087</td>\n",
       "      <td>2085</td>\n",
       "      <td>1955</td>\n",
       "      <td>1843</td>\n",
       "      <td>1741</td>\n",
       "      <td>1706</td>\n",
       "      <td>1705</td>\n",
       "      <td>1686</td>\n",
       "      <td>1675</td>\n",
       "      <td>1276</td>\n",
       "      <td>1272</td>\n",
       "      <td>1207</td>\n",
       "      <td>1019</td>\n",
       "      <td>856</td>\n",
       "      <td>823</td>\n",
       "      <td>804</td>\n",
       "      <td>800</td>\n",
       "      <td>798</td>\n",
       "      <td>795</td>\n",
       "      <td>765</td>\n",
       "      <td>753</td>\n",
       "      <td>747</td>\n",
       "      <td>729</td>\n",
       "      <td>719</td>\n",
       "      <td>714</td>\n",
       "      <td>709</td>\n",
       "      <td>696</td>\n",
       "      <td>646</td>\n",
       "      <td>612</td>\n",
       "      <td>601</td>\n",
       "      <td>588</td>\n",
       "      <td>587</td>\n",
       "      <td>567</td>\n",
       "      <td>561</td>\n",
       "      <td>539</td>\n",
       "      <td>503</td>\n",
       "      <td>491</td>\n",
       "      <td>487</td>\n",
       "      <td>474</td>\n",
       "      <td>451</td>\n",
       "      <td>434</td>\n",
       "      <td>430</td>\n",
       "      <td>417</td>\n",
       "      <td>397</td>\n",
       "      <td>394</td>\n",
       "      <td>347</td>\n",
       "      <td>346</td>\n",
       "      <td>311</td>\n",
       "      <td>283</td>\n",
       "      <td>278</td>\n",
       "      <td>278</td>\n",
       "      <td>216</td>\n",
       "      <td>210</td>\n",
       "      <td>199</td>\n",
       "      <td>163</td>\n",
       "      <td>145</td>\n",
       "      <td>108</td>\n",
       "      <td>106</td>\n",
       "      <td>100</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "model_a  gpt-4-1106-preview  gpt-3.5-turbo-0613  gpt-4-0613  claude-2.1  \\\n",
       "count                  3678                3553        3099        2859   \n",
       "\n",
       "model_a  gpt-4-0314  claude-instant-1  claude-1  vicuna-33b  \\\n",
       "count          2087              2085      1955        1843   \n",
       "\n",
       "model_a  mixtral-8x7b-instruct-v0.1  mistral-medium  vicuna-13b  \\\n",
       "count                          1741            1706        1705   \n",
       "\n",
       "model_a  gpt-3.5-turbo-1106  llama-2-70b-chat  llama-2-13b-chat  claude-2.0  \\\n",
       "count                  1686              1675              1276        1272   \n",
       "\n",
       "model_a  zephyr-7b-beta  palm-2  llama-2-7b-chat  openchat-3.5  \\\n",
       "count              1207    1019              856           823   \n",
       "\n",
       "model_a  mistral-7b-instruct  wizardlm-70b  wizardlm-13b  koala-13b  \\\n",
       "count                    804           800           798        795   \n",
       "\n",
       "model_a  vicuna-7b  oasst-pythia-12b  codellama-34b-instruct  \\\n",
       "count          765               753                     747   \n",
       "\n",
       "model_a  gemini-pro-dev-api  gemini-pro  pplx-70b-online  alpaca-13b  \\\n",
       "count                   729         719              714         709   \n",
       "\n",
       "model_a  yi-34b-chat  gpt-3.5-turbo-0314  chatglm-6b  pplx-7b-online  \\\n",
       "count            696                 646         612             601   \n",
       "\n",
       "model_a  RWKV-4-Raven-14B  tulu-2-dpo-70b  gpt-4-0125-preview  \\\n",
       "count                 588             587                 567   \n",
       "\n",
       "model_a  starling-lm-7b-alpha  qwen-14b-chat  chatglm3-6b  \\\n",
       "count                     561            539          503   \n",
       "\n",
       "model_a  stripedhyena-nous-7b  fastchat-t5-3b  openhermes-2.5-mistral-7b  \\\n",
       "count                     491             487                        474   \n",
       "\n",
       "model_a  mpt-7b-chat  solar-10.7b-instruct-v1.0  deepseek-llm-67b-chat  \\\n",
       "count            451                        434                    430   \n",
       "\n",
       "model_a  gpt-3.5-turbo-0125  dolly-v2-12b  stablelm-tuned-alpha-7b  \\\n",
       "count                   417           397                      394   \n",
       "\n",
       "model_a  guanaco-33b  llama2-70b-steerlm-chat  mpt-30b-chat  chatglm2-6b  \\\n",
       "count            347                      346           311          283   \n",
       "\n",
       "model_a  qwen1.5-72b-chat  llama-13b  gpt4all-13b-snoozy  zephyr-7b-alpha  \\\n",
       "count                 278        278                 216              210   \n",
       "\n",
       "model_a  dolphin-2.2.1-mistral-7b  nous-hermes-2-mixtral-8x7b-dpo  \\\n",
       "count                         199                             163   \n",
       "\n",
       "model_a  falcon-180b-chat  openchat-3.5-0106  qwen1.5-7b-chat  \\\n",
       "count                 145                108              106   \n",
       "\n",
       "model_a  qwen1.5-4b-chat  mistral-7b-instruct-v0.2  \n",
       "count                100                        54  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_a_vc.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90a4e9c0-8628-497f-a455-0ec904413e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>model_b</th>\n",
       "      <th>gpt-4-1106-preview</th>\n",
       "      <th>gpt-3.5-turbo-0613</th>\n",
       "      <th>gpt-4-0613</th>\n",
       "      <th>claude-2.1</th>\n",
       "      <th>claude-instant-1</th>\n",
       "      <th>gpt-4-0314</th>\n",
       "      <th>claude-1</th>\n",
       "      <th>vicuna-33b</th>\n",
       "      <th>mixtral-8x7b-instruct-v0.1</th>\n",
       "      <th>llama-2-70b-chat</th>\n",
       "      <th>vicuna-13b</th>\n",
       "      <th>gpt-3.5-turbo-1106</th>\n",
       "      <th>mistral-medium</th>\n",
       "      <th>llama-2-13b-chat</th>\n",
       "      <th>zephyr-7b-beta</th>\n",
       "      <th>claude-2.0</th>\n",
       "      <th>palm-2</th>\n",
       "      <th>llama-2-7b-chat</th>\n",
       "      <th>wizardlm-70b</th>\n",
       "      <th>vicuna-7b</th>\n",
       "      <th>mistral-7b-instruct</th>\n",
       "      <th>openchat-3.5</th>\n",
       "      <th>koala-13b</th>\n",
       "      <th>wizardlm-13b</th>\n",
       "      <th>gemini-pro-dev-api</th>\n",
       "      <th>yi-34b-chat</th>\n",
       "      <th>oasst-pythia-12b</th>\n",
       "      <th>codellama-34b-instruct</th>\n",
       "      <th>gemini-pro</th>\n",
       "      <th>pplx-70b-online</th>\n",
       "      <th>alpaca-13b</th>\n",
       "      <th>gpt-3.5-turbo-0314</th>\n",
       "      <th>pplx-7b-online</th>\n",
       "      <th>chatglm-6b</th>\n",
       "      <th>tulu-2-dpo-70b</th>\n",
       "      <th>gpt-4-0125-preview</th>\n",
       "      <th>starling-lm-7b-alpha</th>\n",
       "      <th>RWKV-4-Raven-14B</th>\n",
       "      <th>fastchat-t5-3b</th>\n",
       "      <th>qwen-14b-chat</th>\n",
       "      <th>chatglm3-6b</th>\n",
       "      <th>openhermes-2.5-mistral-7b</th>\n",
       "      <th>mpt-7b-chat</th>\n",
       "      <th>solar-10.7b-instruct-v1.0</th>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <th>stripedhyena-nous-7b</th>\n",
       "      <th>dolly-v2-12b</th>\n",
       "      <th>stablelm-tuned-alpha-7b</th>\n",
       "      <th>deepseek-llm-67b-chat</th>\n",
       "      <th>guanaco-33b</th>\n",
       "      <th>llama2-70b-steerlm-chat</th>\n",
       "      <th>mpt-30b-chat</th>\n",
       "      <th>chatglm2-6b</th>\n",
       "      <th>qwen1.5-72b-chat</th>\n",
       "      <th>llama-13b</th>\n",
       "      <th>zephyr-7b-alpha</th>\n",
       "      <th>gpt4all-13b-snoozy</th>\n",
       "      <th>dolphin-2.2.1-mistral-7b</th>\n",
       "      <th>nous-hermes-2-mixtral-8x7b-dpo</th>\n",
       "      <th>falcon-180b-chat</th>\n",
       "      <th>openchat-3.5-0106</th>\n",
       "      <th>qwen1.5-7b-chat</th>\n",
       "      <th>qwen1.5-4b-chat</th>\n",
       "      <th>mistral-7b-instruct-v0.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3709</td>\n",
       "      <td>3530</td>\n",
       "      <td>3066</td>\n",
       "      <td>2724</td>\n",
       "      <td>2051</td>\n",
       "      <td>2035</td>\n",
       "      <td>2023</td>\n",
       "      <td>1877</td>\n",
       "      <td>1804</td>\n",
       "      <td>1753</td>\n",
       "      <td>1743</td>\n",
       "      <td>1666</td>\n",
       "      <td>1609</td>\n",
       "      <td>1331</td>\n",
       "      <td>1194</td>\n",
       "      <td>1184</td>\n",
       "      <td>958</td>\n",
       "      <td>937</td>\n",
       "      <td>844</td>\n",
       "      <td>826</td>\n",
       "      <td>813</td>\n",
       "      <td>809</td>\n",
       "      <td>803</td>\n",
       "      <td>782</td>\n",
       "      <td>757</td>\n",
       "      <td>751</td>\n",
       "      <td>741</td>\n",
       "      <td>727</td>\n",
       "      <td>719</td>\n",
       "      <td>706</td>\n",
       "      <td>694</td>\n",
       "      <td>656</td>\n",
       "      <td>649</td>\n",
       "      <td>649</td>\n",
       "      <td>613</td>\n",
       "      <td>593</td>\n",
       "      <td>573</td>\n",
       "      <td>570</td>\n",
       "      <td>534</td>\n",
       "      <td>533</td>\n",
       "      <td>486</td>\n",
       "      <td>478</td>\n",
       "      <td>477</td>\n",
       "      <td>465</td>\n",
       "      <td>444</td>\n",
       "      <td>423</td>\n",
       "      <td>403</td>\n",
       "      <td>377</td>\n",
       "      <td>365</td>\n",
       "      <td>337</td>\n",
       "      <td>321</td>\n",
       "      <td>287</td>\n",
       "      <td>281</td>\n",
       "      <td>273</td>\n",
       "      <td>269</td>\n",
       "      <td>202</td>\n",
       "      <td>192</td>\n",
       "      <td>174</td>\n",
       "      <td>162</td>\n",
       "      <td>141</td>\n",
       "      <td>136</td>\n",
       "      <td>102</td>\n",
       "      <td>100</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "model_b  gpt-4-1106-preview  gpt-3.5-turbo-0613  gpt-4-0613  claude-2.1  \\\n",
       "count                  3709                3530        3066        2724   \n",
       "\n",
       "model_b  claude-instant-1  gpt-4-0314  claude-1  vicuna-33b  \\\n",
       "count                2051        2035      2023        1877   \n",
       "\n",
       "model_b  mixtral-8x7b-instruct-v0.1  llama-2-70b-chat  vicuna-13b  \\\n",
       "count                          1804              1753        1743   \n",
       "\n",
       "model_b  gpt-3.5-turbo-1106  mistral-medium  llama-2-13b-chat  zephyr-7b-beta  \\\n",
       "count                  1666            1609              1331            1194   \n",
       "\n",
       "model_b  claude-2.0  palm-2  llama-2-7b-chat  wizardlm-70b  vicuna-7b  \\\n",
       "count          1184     958              937           844        826   \n",
       "\n",
       "model_b  mistral-7b-instruct  openchat-3.5  koala-13b  wizardlm-13b  \\\n",
       "count                    813           809        803           782   \n",
       "\n",
       "model_b  gemini-pro-dev-api  yi-34b-chat  oasst-pythia-12b  \\\n",
       "count                   757          751               741   \n",
       "\n",
       "model_b  codellama-34b-instruct  gemini-pro  pplx-70b-online  alpaca-13b  \\\n",
       "count                       727         719              706         694   \n",
       "\n",
       "model_b  gpt-3.5-turbo-0314  pplx-7b-online  chatglm-6b  tulu-2-dpo-70b  \\\n",
       "count                   656             649         649             613   \n",
       "\n",
       "model_b  gpt-4-0125-preview  starling-lm-7b-alpha  RWKV-4-Raven-14B  \\\n",
       "count                   593                   573               570   \n",
       "\n",
       "model_b  fastchat-t5-3b  qwen-14b-chat  chatglm3-6b  \\\n",
       "count               534            533          486   \n",
       "\n",
       "model_b  openhermes-2.5-mistral-7b  mpt-7b-chat  solar-10.7b-instruct-v1.0  \\\n",
       "count                          478          477                        465   \n",
       "\n",
       "model_b  gpt-3.5-turbo-0125  stripedhyena-nous-7b  dolly-v2-12b  \\\n",
       "count                   444                   423           403   \n",
       "\n",
       "model_b  stablelm-tuned-alpha-7b  deepseek-llm-67b-chat  guanaco-33b  \\\n",
       "count                        377                    365          337   \n",
       "\n",
       "model_b  llama2-70b-steerlm-chat  mpt-30b-chat  chatglm2-6b  qwen1.5-72b-chat  \\\n",
       "count                        321           287          281               273   \n",
       "\n",
       "model_b  llama-13b  zephyr-7b-alpha  gpt4all-13b-snoozy  \\\n",
       "count          269              202                 192   \n",
       "\n",
       "model_b  dolphin-2.2.1-mistral-7b  nous-hermes-2-mixtral-8x7b-dpo  \\\n",
       "count                         174                             162   \n",
       "\n",
       "model_b  falcon-180b-chat  openchat-3.5-0106  qwen1.5-7b-chat  \\\n",
       "count                 141                136              102   \n",
       "\n",
       "model_b  qwen1.5-4b-chat  mistral-7b-instruct-v0.2  \n",
       "count                100                        46  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_b_vc.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04dc3ad6-1834-4141-a638-01247aef49ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "winner_a count:\n",
      "                count\n",
      "winner_model_a       \n",
      "0               37413\n",
      "1               20064\n",
      "------------------------------\n",
      "winner_b count:\n",
      "                count\n",
      "winner_model_b       \n",
      "0               37825\n",
      "1               19652\n",
      "------------------------------\n",
      "winner_tie count:\n",
      "            count\n",
      "winner_tie       \n",
      "0           39716\n",
      "1           17761\n"
     ]
    }
   ],
   "source": [
    "print(\"winner_a count:\")\n",
    "print(winner_a_count)\n",
    "print(\"-\"*30)\n",
    "print(\"winner_b count:\")\n",
    "print(winner_b_count)\n",
    "print(\"-\"*30)\n",
    "print(\"winner_tie count:\")\n",
    "print(winner_tie_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cf0644-d4dc-42b8-9522-938666c97ee3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
